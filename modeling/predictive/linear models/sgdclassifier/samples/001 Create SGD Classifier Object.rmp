<?xml version="1.0" encoding="UTF-8"?><process version="9.5.001">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.4.000" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="python_operator_framework:create_python_learner" compatibility="0.0.004-SNAPSHOT" expanded="true" height="82" name="Create Learner Object (2)" width="90" x="380" y="289">
        <parameter key="description" value="Train SGD Classifier"/>
        <parameter key="train script" value="from sklearn import linear_model&#10;&#10;import numpy as np&#10;import pandas as pd&#10;&#10;&#10;def rm_main(params,data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Fits the linear SGD classifier.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame created from the RapidMiner ExampleSet by the Execute Python operator.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;model&#10;&#9;&#9;Fitted SGD classifier.&#10;&#9;data&#10;&#9;&#9;pd.DataFrame passed as argument.&#10;&#9;&quot;&quot;&quot;&#10;&#9;params_dict = process_params(params)&#10;&#9;features, labels = separate_features_labels(data)&#10;&#9;clf = linear_model.SGDClassifier(loss=params_dict['loss'], penalty=params_dict['penalty'], alpha=params_dict['alpha'],&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;l1_ratio=params_dict['l1_ratio'], fit_intercept=params_dict['fit_intercept'],&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;max_iter=params_dict['max_iter'], shuffle=params_dict['shuffle'], verbose=params_dict['verbose'],&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;epsilon=params_dict['epsilon'], random_state=1,&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;learning_rate=params_dict['learning_rate'], eta0=params_dict['eta0'],&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;power_t=params_dict['power_t'], class_weight=params_dict['class_weight'], warm_start=params_dict['warm_start'],&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;average=params_dict['average'])&#10;&#9;model = clf.fit(np.array(features), np.array(labels))&#10;&#9;return model, wrapOutputHTML(model,features,labels)&#10;&#9;&#10;def wrapOutputHTML(model,features,label):&#10;&#9;&#10;&#9;outputs = '&lt;h3&gt;&lt;span color=\'red\'&gt;&lt;h1&gt; name of features&lt;/h1&gt; &lt;br&gt;'&#10;&#9;for col in features.columns: &#10;&#9;&#9;outputs += str(col)&#10;&#9;&#9;outputs += ' -- '&#10;&#9;outputs += '&lt;/span&gt;&lt;/h3&gt;'&#10;&#9;outputs += &quot;&lt;br&gt;&lt;h2&gt; Model Coef&lt;/h2&gt;&lt;br&gt;&quot;&#10;&#9;dataFrame = pd.DataFrame.from_records(model.coef_).T&#10;&#9;outputs +=  dataFrame.to_html().replace(&quot;\n&quot;,&quot;&quot;).strip()&#10;&#9;outputs += &quot;&lt;br&gt;&quot;&#10;&#9;outputs += &quot;&lt;br&gt;&quot;&#10;&#9;return outputs&#10;'''&#10;Functiosn below are helper functions. They can also be found in rm_utilities package in pip&#10;'''&#10;def separate_features_labels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and labels in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features to train the SGD classifier on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels to pass to the SGD classifier during training.&#10;&#9;&quot;&quot;&quot;&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#10;&#9;return features, labels&#10;&#10;def process_params(params):&#10;    for i in params.index:&#10;        print(params['type'][i])&#10;        if (params['type'][i] == 'ParameterTypeInt'):&#10;            params['value'][i] = int(params['value'][i])&#10;        elif (params['type'][i] == 'ParameterTypeString'):&#10;            params['value'][i] = __process_parameter_string__(params['value'][i])&#10;        elif (params['type'][i] == 'ParameterTypeDouble'):&#10;            params['value'][i] = float(params['value'][i])&#10;        elif (params['type'][i] == 'ParameterTypeBoolean'):&#10;            params['value'][i] = __process_parameter_string__(params['value'][i])&#10;        elif (params['type'][i] == 'ParameterTypeStringCategory'):&#10;            params['value'][i] = __process_parameter_string__(params['value'][i])&#10;        elif (params['type'][i] == 'ParameterTypeCategory'):&#10;            params['value'][i] = __process_parameter_string__(params['value'][i])&#10;    params_dict = dict(zip(params.key, params.value))&#10;    # replace string None with KeyWord None&#10;    # for key,value in params_dict.items():&#10;    #   if value == 'None':&#10;    #       params_dict[key] = None&#10;    return params_dict&#10;&#10;def __process_parameter_string__(strvalue):&#10;    if (strvalue == 'None'):&#10;        strvalue = None&#10;    if strvalue == &quot;True&quot;:&#10;        return True&#10;    if strvalue == &quot;False&quot;:&#10;        return False&#10;    return strvalue&#10;&#10;&#10;def processString(strvalue):&#10;&#9;if(strvalue == 'None'):&#10;&#9;&#9;strvalue = None&#10;&#9;return strvalue&#10;&#9;&#10;"/>
        <parameter key="apply script" value="from statsmodels.tsa.arima_model import ARIMA&#10;&#10;import numpy as np&#10;import pandas as pd&#10;&#10;package_dict = {'LabelPropagation': 'scikit-learn', 'PassiveAggressiveClassifier': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SGDClassifier': 'scikit-learn', 'SGDRegressor': 'scikit-learn', 'Earth': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SMOTE': 'scikit-learn', 'ARIMAResultsWrapper': 'statsmodels'}&#10;&#10;def rm_main(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn or statsmodels model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;package_name = get_package_name(stored_model)&#10;&#9;if package_name == 'scikit-learn':&#10;&#9;&#9;data, stored_model = apply_sklearn(stored_model, data)&#10;&#9;elif package_name == 'statsmodels':&#10;&#9;&#9;data, stored_model = apply_statsmodels(stored_model, data)&#10;&#10;&#9;return data&#10;&#10;'''&#10;&#9;Functions below are helper functions. They can also be found in rm_utilities package.&#10;'''&#10;def get_package_name(stored_model):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Returns the package name of the stored_model in order to call the right method for performing classification or&#10;&#9;regression. The methods are different for models in scikit-learn and statsmodels packages.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return package_dict[type(stored_model).__name__]&#10;&#10;&#10;def preprocessing_sklearn(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and labels/targets in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features to fit the model on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels/targets to pass to the model during training.&#10;&#9;&quot;&quot;&quot;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#9;&#10;&#9;return features, labels&#10;&#10;&#10;def apply_sklearn(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;features, labels = preprocessing_sklearn(data)&#10;&#10;&#9;predicted_labels = pd.DataFrame(stored_model.predict(features))&#10;&#9;predictionColumnName = 'Prediction(' +  labels.name + ')'&#10;&#9;data[predictionColumnName] = predicted_labels&#10;&#9;data.rm_metadata[predictionColumnName] = (data.rm_metadata[labels.name][0],&quot;prediction&quot;)&#10;&#9;data.rm_metadata[labels.name] = (data.rm_metadata[labels.name][0],&quot;label&quot;)&#10;&#9;return data, stored_model&#10;&#10;&#10;def __getnewargs__(self):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Overrides a method that causes a bug when trying to serialise the ARIMA model.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return ((self.endog), (self.k_lags, self.k_diff, self.k_ma))&#10;&#10;&#10;def preprocessing_statsmodels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Preprocesses the data to prepare for performing prediction with the ARIMA model.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with the dataset.&#10;&#9;Returns&#10;&#9;----------&#10;&#9;date_time_column&#10;&#9;&#9;pd.Series with date_time data.&#10;&#9;prediction_column&#10;&#9;&#9;pd.Series with target data.&#10;&#9;&quot;&quot;&quot;&#10;&#9;date_time_column = pd.Series()&#10;&#9;prediction_column = pd.Series()&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_type == 'date_time':&#10;&#9;&#9;&#9;date_time_column = data[name]&#10;&#9;&#9;if attribute_role == 'prediction':&#10;&#9;&#9;&#9;prediction_column = data[name]&#10;&#10;&#9;return date_time_column, prediction_column&#10;&#10;&#10;def apply_statsmodels(model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9; Performs out-of-sample forecast on data.&#10;&#10;&#9; Parameters&#10;&#9; ----------&#10;&#9; model : statsmodels.tsa.arima_model.ARIMA&#10;&#9;&#9;Pre-trained ARIMA model.&#10;&#9; data : pd.DataFrame&#10;&#9;&#9;DataFrame with data on which to forecast.&#10;&#10;&#9; Returns&#10;&#9; -------&#10;&#9; result_df&#10;&#9;&#9; DataFrame with out-of-sample forecasts.&#10;&#9; model&#10;&#9;&#9; Fitted ARIMA model.&#10;&#9; &quot;&quot;&quot;&#10;&#9;ARIMA.__getnewargs__ = __getnewargs__&#10;&#10;&#9;date_time_column, prediction_column = preprocessing_statsmodels(data)&#10;&#9;start = date_time_column.iloc[0]&#10;&#9;end = date_time_column.iloc[-1]&#10;&#10;&#9;predictions = model.predict(start=start, end=end, typ='levels')&#10;&#9;result_df = pd.DataFrame(data=predictions.values, columns=[prediction_column.name])&#10;&#9;result_df[date_time_column.name] = date_time_column&#10;&#9;result_df.rm_metadata = {date_time_column.name: ('date_time', 'id'), prediction_column.name: ('real', 'prediction')}&#10;&#10;&#9;return result_df, model&#10;&#10;&#10;"/>
        <parameter key="params XML definition" value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&lt;model name=&quot;SGDClassifier&quot;&gt;&#10;&#9;&lt;parameter name=&quot;loss&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The loss function to be used. Defaults to ‘hinge’, which gives a linear SVM. The ‘log’ loss gives logistic regression, a probabilistic classifier. ‘modified_huber’ is another smooth loss that brings tolerance to outliers as well as probability estimates. ‘squared_hinge’ is like hinge but is quadratically penalized. ‘perceptron’ is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;        &lt;value&gt;hinge&lt;/value&gt;&#10;        &lt;value&gt;log&lt;/value&gt;&#10;        &lt;value&gt;modified_huber&lt;/value&gt;&#10;        &lt;value&gt;squared_hinge&lt;/value&gt;&#10;        &lt;value&gt;perceptron&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;squared_loss&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;huber&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;epsilon_insensitive&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;squared_epsilon_insensitive&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;hinge&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;epsilon&quot; parent=&quot;loss&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Epsilon in the epsilon-insensitive loss functions.&lt;/description&gt;&#10;&#9;&#9;&lt;activation_value&gt;huber&lt;/activation_value&gt;&#10;&#9;&#9;&lt;activation_value&gt;epsilon_insensitive&lt;/activation_value&gt;&#10;&#9;&#9;&lt;activation_value&gt;squared_epsilon_insensitive&lt;/activation_value&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.01&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;penalty&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The penalty to be used.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;&#9;&#9;&lt;value&gt;None&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;l2&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;l1&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;elasticnet&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;l2&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;alpha&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Constant that multiplies the regularization term.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.0001&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;l1_ratio&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Elastic net mixing parameter.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;1&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.15&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;fit_intercept&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;True&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;max_iter&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The maximum number of passes over the training data (aka epochs).&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;5&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;shuffle&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Whether the training data should be shuffled after each epoch.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;False&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;verbose&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Verbosity level.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;        &lt;min&gt;0&lt;/min&gt;&#10;        &lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;random_state&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Seed of the pseudo random number generator to use when shuffling the data.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;        &lt;min&gt;0&lt;/min&gt;&#10;        &lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;learning_rate&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Learning rate schedule.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;&#9;&#9;&lt;value&gt;constant&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;optimal&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;invscaling&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;optimal&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;    &lt;parameter name=&quot;n_jobs&quot; is_keyword=&quot;true&quot;&gt;&#10;        &lt;description&gt;Number of CPUs to use to do the One Versus All for multi-class problems.&lt;/description&gt;&#10;        &lt;type&gt;int&lt;/type&gt;&#10;        &lt;min&gt;-1&lt;/min&gt;&#10;        &lt;max&gt;64&lt;/max&gt;&#10;        &lt;default&gt;-1&lt;/default&gt;&#10;    &lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;eta0&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Initial learning rate.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.01&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;power_t&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Exponent for inverse scaling learning rate.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.5&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;    &lt;parameter name=&quot;average&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Whether to compute the averaged SGD weights and store the result.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;True&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;warm_start&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Whether to reuse the solution of the previous call to fit as initialisation.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;True&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;parameter name=&quot;class_weight&quot; is_keyword=&quot;true&quot;&gt;&#10;        &lt;description&gt;Weights associated with classes.&lt;/description&gt;&#10;        &lt;type&gt;string&lt;/type&gt;&#10;        &lt;value&gt;None&lt;/value&gt;&#10;        &lt;value&gt;balanced&lt;/value&gt;&#10;        &lt;default&gt;balanced&lt;/default&gt;&#10;    &lt;/parameter&gt;&#10;&lt;/model&gt;"/>
      </operator>
      <operator activated="true" class="store" compatibility="9.5.001" expanded="true" height="68" name="Store" width="90" x="514" y="289">
        <parameter key="repository_entry" value="SGD Classifier"/>
      </operator>
      <connect from_op="Create Learner Object (2)" from_port="pythonLearner" to_op="Store" to_port="input"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
      <portSpacing port="sink_result 3" spacing="0"/>
    </process>
  </operator>
</process>
