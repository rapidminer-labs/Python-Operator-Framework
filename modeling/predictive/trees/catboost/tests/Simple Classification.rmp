<?xml version="1.0" encoding="UTF-8"?><process version="9.5.000">
  <context>
    <input/>
    <output/>
    <macros/>
  </context>
  <operator activated="true" class="process" compatibility="9.5.000" expanded="true" name="Process">
    <parameter key="logverbosity" value="init"/>
    <parameter key="random_seed" value="2001"/>
    <parameter key="send_mail" value="never"/>
    <parameter key="notification_email" value=""/>
    <parameter key="process_duration_for_mail" value="30"/>
    <parameter key="encoding" value="SYSTEM"/>
    <process expanded="true">
      <operator activated="true" class="retrieve" compatibility="9.5.000" expanded="true" height="68" name="Retrieve Sonar" width="90" x="45" y="136">
        <parameter key="repository_entry" value="//Samples/data/Sonar"/>
      </operator>
      <operator activated="false" class="h2o:gradient_boosted_trees" compatibility="9.3.001" expanded="true" height="103" name="Gradient Boosted Trees" width="90" x="447" y="391">
        <parameter key="number_of_trees" value="100"/>
        <parameter key="reproducible" value="false"/>
        <parameter key="maximum_number_of_threads" value="4"/>
        <parameter key="use_local_random_seed" value="false"/>
        <parameter key="local_random_seed" value="1992"/>
        <parameter key="maximal_depth" value="10"/>
        <parameter key="min_rows" value="10.0"/>
        <parameter key="min_split_improvement" value="0.0"/>
        <parameter key="number_of_bins" value="20"/>
        <parameter key="learning_rate" value="0.01"/>
        <parameter key="sample_rate" value="1.0"/>
        <parameter key="distribution" value="AUTO"/>
        <parameter key="early_stopping" value="false"/>
        <parameter key="stopping_rounds" value="1"/>
        <parameter key="stopping_metric" value="AUTO"/>
        <parameter key="stopping_tolerance" value="0.001"/>
        <parameter key="max_runtime_seconds" value="0"/>
        <list key="expert_parameters"/>
      </operator>
      <operator activated="false" class="select_attributes" compatibility="9.5.000" expanded="true" height="82" name="Select Attributes" width="90" x="179" y="442">
        <parameter key="attribute_filter_type" value="single"/>
        <parameter key="attribute" value="class"/>
        <parameter key="attributes" value=""/>
        <parameter key="use_except_expression" value="false"/>
        <parameter key="value_type" value="attribute_value"/>
        <parameter key="use_value_type_exception" value="false"/>
        <parameter key="except_value_type" value="time"/>
        <parameter key="block_type" value="attribute_block"/>
        <parameter key="use_block_type_exception" value="false"/>
        <parameter key="except_block_type" value="value_matrix_row_start"/>
        <parameter key="invert_selection" value="true"/>
        <parameter key="include_special_attributes" value="true"/>
      </operator>
      <operator activated="true" class="python_operator_framework:create_python_learner" compatibility="0.0.004-SNAPSHOT" expanded="true" height="82" name="Create Learner Object" width="90" x="380" y="238">
        <parameter key="train script" value="from sklearn import linear_model&#10;import numpy as np&#10;import pandas as pd&#10;&#10;&#10;def rm_main(params,data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;params: pd.DataFrame&#10;&#9;&#9;DataFrame created by RapidMiner that provides the parameter set during run time from RapidMiner. Best ot convert them to dictionary for easier use later on&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame created from the RapidMiner ExampleSet by the Execute Python operator.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;model&#10;&#9;&#9;Fitted Model&#10;&#9;HTML representation of the model &#10;&#9;&#9;&#10;&#9;&quot;&quot;&quot;&#10;&#9;##Convert the params to dictionary representation for easier acces as needed&#10;&#9;params_dict = process_params(params)&#10;&#9;##Seperate features and lable into seperate DataFrames since lot of Python implementations prefer it that way&#10;&#9;features, labels = separate_features_labels(data)&#10;&#10;&#9;#Below is an example of how you will invoke the learner method and pass parameters to it. NOTICE THE TYPE CASTING.&#10;&#9;clf = linear_model.SGDClassifier(loss=params_dict['loss'], penalty=params_dict['penalty'], alpha=float(params_dict['alpha']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;l1_ratio=float(params_dict['l1_ratio']), fit_intercept=bool(params_dict['fit_intercept']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;max_iter=int(params_dict['max_iter']), shuffle=bool(params_dict['shuffle']), verbose=int(params_dict['verbose']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;epsilon=float(params_dict['epsilon']), random_state=1,&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;learning_rate=params_dict['learning_rate'], eta0=float(params_dict['eta0']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;power_t=float(params_dict['power_t']), class_weight=params_dict['class_weight'], warm_start=bool(params_dict['warm_start']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;average=bool(params_dict['average']))&#10;&#9;model = clf.fit(np.array(features), np.array(labels))&#10;&#9;&#10;&#9;### Once you have build a model, you can return than and HTML View of it if needed&#10;&#9;return model, wrapOutputHTML(model,features,labels)&#10;&#10;def wrapOutputHTML(model,features,label):&#10;&#9;&quot;&quot;&quot;&#10;&#9; This is just a method that builds an HTML output of what you would like to display about the model&#10;&#9;&quot;&quot;&quot;&#10;&#9;outputs = '&lt;h3&gt;&lt;span color=\'red\'&gt;&lt;h1&gt; name of features&lt;/h1&gt; &lt;br&gt;'&#10;&#9;for col in features.columns: &#10;&#9;&#9;outputs += str(col)&#10;&#9;&#9;outputs += ' -- '&#10;&#9;outputs += '&lt;/span&gt;&lt;/h3&gt;'&#10;&#9;outputs += &quot;&lt;br&gt;&lt;h2&gt; Model Coef&lt;/h2&gt;&lt;br&gt;&quot;&#10;&#9;dataFrame = pd.DataFrame.from_records(model.coef_).T&#10;&#9;outputs +=  dataFrame.to_html().replace(&quot;\n&quot;,&quot;&quot;).strip()&#10;&#9;outputs += &quot;&lt;br&gt;&quot;&#10;&#9;outputs += &quot;&lt;br&gt;&quot;&#10;&#9;return outputs&#10;&#10;&#10;def process_params(params):&#10;&#10;&#9;params_dict = dict(zip(params.key,params.value))&#10;&#9;#replace string None with KeyWord None&#10;&#9;for key,value in params_dict.items():&#10;&#9;&#9;if value == 'None':&#10;&#9;&#9;&#9;params_dict[key] = None&#10;&#9;return params_dict&#10;&#10;def separate_features_labels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and labels in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features to train the SGD classifier on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels to pass to the SGD classifier during training.&#10;&#9;&quot;&quot;&quot;&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#10;&#9;return features, labels&#10;&#10;&#10;"/>
        <parameter key="train file" value="C:\Users\MartinSchmitz\Work\ExtensionDevelopment\python-operators\modeling\predictive\trees\catboost\train.py"/>
        <parameter key="apply script" value="from statsmodels.tsa.arima_model import ARIMA&#10;&#10;import numpy as np&#10;import pandas as pd&#10;&#10;# This is a generic script that handles both scikit learn as well as statsmodel, &#10;# you need to provide the name of the algorithm and map it in this dictionary&#10;# The Key here comes from the XML of Params where you can specify the &lt;model name=&quot;somename&quot;&gt;&#10;package_dict = {'LabelPropagation': 'scikit-learn', 'PassiveAggressiveClassifier': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SGDClassifier': 'scikit-learn', 'SGDRegressor': 'scikit-learn', 'Earth': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SMOTE': 'scikit-learn', 'ARIMAResultsWrapper': 'statsmodels'}&#10;&#10;def rm_main(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn or statsmodels model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;    package_name = get_package_name(stored_model)&#10;&#9;if package_name == 'scikit-learn':&#10;&#9;data, stored_model = apply_sklearn(stored_model, data)&#10;&#9;elif package_name == 'statsmodels':&#10;&#9;data, stored_model = apply_statsmodels(stored_model, data)&#10;&#10;&#9;return data&#10;&#10;def get_package_name(stored_model):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Returns the package name of the stored_model in order to call the right method for performing classification or&#10;&#9;regression. The methods are different for models in scikit-learn and statsmodels packages.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return package_dict[type(stored_model).__name__]&#10;&#10;&#10;def preprocessing_sklearn(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and labels/targets in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features to fit the model on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels/targets to pass to the model during training.&#10;&#9;&quot;&quot;&quot;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#9;&#10;&#9;return features, labels&#10;&#10;&#10;def apply_sklearn(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;features, labels = preprocessing_sklearn(data)&#10;&#10;&#9;predicted_labels = pd.DataFrame(stored_model.predict(features))&#10;&#9;predictionColumnName = 'Prediction(' +  labels.name + ')'&#10;&#9;data[predictionColumnName] = predicted_labels&#10;&#9;data.rm_metadata[predictionColumnName] = (&quot;nominal&quot;,&quot;prediction&quot;)&#10;&#9;data.rm_metadata[labels.name] = (&quot;nominal&quot;,&quot;label&quot;)&#10;&#9;return data, stored_model&#10;&#10;&#10;def __getnewargs__(self):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Overrides a method that causes a bug when trying to serialise the ARIMA model.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return ((self.endog), (self.k_lags, self.k_diff, self.k_ma))&#10;&#10;&#10;def preprocessing_statsmodels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Preprocesses the data to prepare for performing prediction with the ARIMA model.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with the dataset.&#10;&#9;Returns&#10;&#9;----------&#10;&#9;date_time_column&#10;&#9;&#9;pd.Series with date_time data.&#10;&#9;prediction_column&#10;&#9;&#9;pd.Series with target data.&#10;&#9;&quot;&quot;&quot;&#10;&#9;date_time_column = pd.Series()&#10;&#9;prediction_column = pd.Series()&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_type == 'date_time':&#10;&#9;&#9;&#9;date_time_column = data[name]&#10;&#9;&#9;if attribute_role == 'prediction':&#10;&#9;&#9;&#9;prediction_column = data[name]&#10;&#10;&#9;return date_time_column, prediction_column&#10;&#10;&#10;def apply_statsmodels(model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9; Performs out-of-sample forecast on data.&#10;&#10;&#9; Parameters&#10;&#9; ----------&#10;&#9; model : statsmodels.tsa.arima_model.ARIMA&#10;&#9;&#9;Pre-trained ARIMA model.&#10;&#9; data : pd.DataFrame&#10;&#9;&#9;DataFrame with data on which to forecast.&#10;&#10;&#9; Returns&#10;&#9; -------&#10;&#9; result_df&#10;&#9;&#9; DataFrame with out-of-sample forecasts.&#10;&#9; model&#10;&#9;&#9; Fitted ARIMA model.&#10;&#9; &quot;&quot;&quot;&#10;&#9;ARIMA.__getnewargs__ = __getnewargs__&#10;&#10;&#9;date_time_column, prediction_column = preprocessing_statsmodels(data)&#10;&#9;start = date_time_column.iloc[0]&#10;&#9;end = date_time_column.iloc[-1]&#10;&#10;&#9;predictions = model.predict(start=start, end=end, typ='levels')&#10;&#9;result_df = pd.DataFrame(data=predictions.values, columns=[prediction_column.name])&#10;&#9;result_df[date_time_column.name] = date_time_column&#10;&#9;result_df.rm_metadata = {date_time_column.name: ('date_time', 'id'), prediction_column.name: ('real', 'prediction')}&#10;&#10;&#9;return result_df, model&#10;"/>
        <parameter key="apply file" value="C:\Users\MartinSchmitz\Work\ExtensionDevelopment\python-operators\modeling\predictive\trees\catboost\apply.py"/>
        <parameter key="params XML definition" value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&#10;&lt;model name=&quot;somename&quot;&gt;&#10;&lt;!-- this will show up as drop down --&gt;&#10;&#9;&lt;parameter name=&quot;loss&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The loss function to be used. Defaults to ‘hinge’, which gives a linear SVM. The ‘log’ loss gives logistic regression, a probabilistic classifier. ‘modified_huber’ is another smooth loss that brings tolerance to outliers as well as probability estimates. ‘squared_hinge’ is like hinge but is quadratically penalized. ‘perceptron’ is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;        &lt;value&gt;hinge&lt;/value&gt;&#10;        &lt;value&gt;log&lt;/value&gt;&#10;        &lt;value&gt;modified_huber&lt;/value&gt;&#10;        &lt;value&gt;squared_hinge&lt;/value&gt;&#10;        &lt;value&gt;perceptron&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;squared_loss&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;huber&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;epsilon_insensitive&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;squared_epsilon_insensitive&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;hinge&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as float. The parameters is only visible if parent has values matching the activation_value--&gt;&#10;&#9;&lt;parameter name=&quot;epsilon&quot; parent=&quot;loss&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Epsilon in the epsilon-insensitive loss functions.&lt;/description&gt;&#10;&#9;&#9;&lt;activation_value&gt;huber&lt;/activation_value&gt;&#10;&#9;&#9;&lt;activation_value&gt;epsilon_insensitive&lt;/activation_value&gt;&#10;&#9;&#9;&lt;activation_value&gt;squared_epsilon_insensitive&lt;/activation_value&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.01&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as drop down --&gt;&#10;&#9;&lt;parameter name=&quot;penalty&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The penalty to be used.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;&#9;&#9;&lt;value&gt;none&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;l2&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;l1&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;elasticnet&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;l2&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as numeric input box supporting real numbers--&gt;&#10;&#9;&lt;parameter name=&quot;alpha&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Constant that multiplies the regularization term.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.0001&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as checkbox--&gt;&#10;&#9;&lt;parameter name=&quot;fit_intercept&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;True&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as numeric input box supporting Integers only--&gt;&#10;&#9;&lt;parameter name=&quot;max_iter&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The maximum number of passes over the training data (aka epochs).&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;5&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;    &lt;parameter name=&quot;n_jobs&quot; is_keyword=&quot;true&quot;&gt;&#10;        &lt;description&gt;Number of CPUs to use to do the One Versus All for multi-class problems.&lt;/description&gt;&#10;        &lt;type&gt;int&lt;/type&gt;&#10;        &lt;min&gt;-1&lt;/min&gt;&#10;        &lt;max&gt;64&lt;/max&gt;&#10;        &lt;default&gt;-1&lt;/default&gt;&#10;    &lt;/parameter&gt;&#10;    &lt;!-- this will only allow positive real numbers --&gt;&#10;&#9;&lt;parameter name=&quot;eta0&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Initial learning rate.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.01&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&lt;/model&gt;"/>
        <parameter key="learner parameters" value="C:\Users\MartinSchmitz\Work\ExtensionDevelopment\python-operators\modeling\predictive\trees\catboost\parameters.xml"/>
      </operator>
      <operator activated="true" class="python_operator_framework:process_python_learner" compatibility="0.0.004-SNAPSHOT" expanded="true" height="82" name="Build Python Model" width="90" x="514" y="136">
        <parameter key="iterations" value="5"/>
        <parameter key="learning_rate" value="0.03"/>
      </operator>
      <operator activated="false" class="python_operator_framework:create_python_learner" compatibility="0.0.004-SNAPSHOT" expanded="true" height="82" name="Create Learner Object (2)" width="90" x="313" y="391">
        <parameter key="train script" value="from sklearn import linear_model&#10;import numpy as np&#10;import pandas as pd&#10;&#10;&#10;def rm_main(params,data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;params: pd.DataFrame&#10;&#9;&#9;DataFrame created by RapidMiner that provides the parameter set during run time from RapidMiner. Best ot convert them to dictionary for easier use later on&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame created from the RapidMiner ExampleSet by the Execute Python operator.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;model&#10;&#9;&#9;Fitted Model&#10;&#9;HTML representation of the model &#10;&#9;&#9;&#10;&#9;&quot;&quot;&quot;&#10;&#9;##Convert the params to dictionary representation for easier acces as needed&#10;&#9;params_dict = process_params(params)&#10;&#9;##Seperate features and lable into seperate DataFrames since lot of Python implementations prefer it that way&#10;&#9;features, labels = separate_features_labels(data)&#10;&#10;&#9;#Below is an example of how you will invoke the learner method and pass parameters to it. NOTICE THE TYPE CASTING.&#10;&#9;clf = linear_model.SGDClassifier(loss=params_dict['loss'], penalty=params_dict['penalty'], alpha=float(params_dict['alpha']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;l1_ratio=float(params_dict['l1_ratio']), fit_intercept=bool(params_dict['fit_intercept']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;max_iter=int(params_dict['max_iter']), shuffle=bool(params_dict['shuffle']), verbose=int(params_dict['verbose']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;epsilon=float(params_dict['epsilon']), random_state=1,&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;learning_rate=params_dict['learning_rate'], eta0=float(params_dict['eta0']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;power_t=float(params_dict['power_t']), class_weight=params_dict['class_weight'], warm_start=bool(params_dict['warm_start']),&#10;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;&#9;average=bool(params_dict['average']))&#10;&#9;model = clf.fit(np.array(features), np.array(labels))&#10;&#9;&#10;&#9;### Once you have build a model, you can return than and HTML View of it if needed&#10;&#9;return model, wrapOutputHTML(model,features,labels)&#10;&#10;def wrapOutputHTML(model,features,label):&#10;&#9;&quot;&quot;&quot;&#10;&#9; This is just a method that builds an HTML output of what you would like to display about the model&#10;&#9;&quot;&quot;&quot;&#10;&#9;outputs = '&lt;h3&gt;&lt;span color=\'red\'&gt;&lt;h1&gt; name of features&lt;/h1&gt; &lt;br&gt;'&#10;&#9;for col in features.columns: &#10;&#9;&#9;outputs += str(col)&#10;&#9;&#9;outputs += ' -- '&#10;&#9;outputs += '&lt;/span&gt;&lt;/h3&gt;'&#10;&#9;outputs += &quot;&lt;br&gt;&lt;h2&gt; Model Coef&lt;/h2&gt;&lt;br&gt;&quot;&#10;&#9;dataFrame = pd.DataFrame.from_records(model.coef_).T&#10;&#9;outputs +=  dataFrame.to_html().replace(&quot;\n&quot;,&quot;&quot;).strip()&#10;&#9;outputs += &quot;&lt;br&gt;&quot;&#10;&#9;outputs += &quot;&lt;br&gt;&quot;&#10;&#9;return outputs&#10;&#10;&#10;def process_params(params):&#10;&#10;&#9;params_dict = dict(zip(params.key,params.value))&#10;&#9;#replace string None with KeyWord None&#10;&#9;for key,value in params_dict.items():&#10;&#9;&#9;if value == 'None':&#10;&#9;&#9;&#9;params_dict[key] = None&#10;&#9;return params_dict&#10;&#10;def separate_features_labels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and labels in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features to train the SGD classifier on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels to pass to the SGD classifier during training.&#10;&#9;&quot;&quot;&quot;&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#10;&#9;return features, labels&#10;&#10;&#10;"/>
        <parameter key="apply script" value="from statsmodels.tsa.arima_model import ARIMA&#10;&#10;import numpy as np&#10;import pandas as pd&#10;&#10;# This is a generic script that handles both scikit learn as well as statsmodel, &#10;# you need to provide the name of the algorithm and map it in this dictionary&#10;# The Key here comes from the XML of Params where you can specify the &lt;model name=&quot;somename&quot;&gt;&#10;package_dict = {'LabelPropagation': 'scikit-learn', 'PassiveAggressiveClassifier': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SGDClassifier': 'scikit-learn', 'SGDRegressor': 'scikit-learn', 'Earth': 'scikit-learn',&#10;&#9;&#9;&#9;&#9;'SMOTE': 'scikit-learn', 'ARIMAResultsWrapper': 'statsmodels'}&#10;&#10;def rm_main(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn or statsmodels model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn or statsmodels model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;    package_name = get_package_name(stored_model)&#10;&#9;if package_name == 'scikit-learn':&#10;&#9;data, stored_model = apply_sklearn(stored_model, data)&#10;&#9;elif package_name == 'statsmodels':&#10;&#9;data, stored_model = apply_statsmodels(stored_model, data)&#10;&#10;&#9;return data&#10;&#10;def get_package_name(stored_model):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Returns the package name of the stored_model in order to call the right method for performing classification or&#10;&#9;regression. The methods are different for models in scikit-learn and statsmodels packages.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return package_dict[type(stored_model).__name__]&#10;&#10;&#10;def preprocessing_sklearn(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Using the RapidMiner attribute metadata, separates features and labels/targets in the DataFrame passed as argument.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;Dataset.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;features&#10;&#9;&#9;pd.DataFrame with features to fit the model on.&#10;&#9;labels&#10;&#9;&#9;pd.DataFrame with labels/targets to pass to the model during training.&#10;&#9;&quot;&quot;&quot;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_role == 'label':&#10;&#9;&#9;&#9;labels = data[name]&#10;&#10;&#9;features = data.drop(labels.name, axis=1)&#10;&#9;&#10;&#9;return features, labels&#10;&#10;&#10;def apply_sklearn(stored_model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Applies a scikit-learn model to previously unseen data.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model.&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with data to perform predictions on.&#10;&#10;&#9;Returns&#10;&#9;-------&#10;&#9;data&#10;&#9;&#9;DataFrame with model predictions.&#10;&#9;stored_model&#10;&#9;&#9;Trained scikit-learn model passed in method arguments.&#10;&#9;&quot;&quot;&quot;&#10;&#9;features, labels = preprocessing_sklearn(data)&#10;&#10;&#9;predicted_labels = pd.DataFrame(stored_model.predict(features))&#10;&#9;predictionColumnName = 'Prediction(' +  labels.name + ')'&#10;&#9;data[predictionColumnName] = predicted_labels&#10;&#9;data.rm_metadata[predictionColumnName] = (&quot;nominal&quot;,&quot;prediction&quot;)&#10;&#9;data.rm_metadata[labels.name] = (&quot;nominal&quot;,&quot;label&quot;)&#10;&#9;return data, stored_model&#10;&#10;&#10;def __getnewargs__(self):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Overrides a method that causes a bug when trying to serialise the ARIMA model.&#10;&#9;&quot;&quot;&quot;&#10;&#9;return ((self.endog), (self.k_lags, self.k_diff, self.k_ma))&#10;&#10;&#10;def preprocessing_statsmodels(data):&#10;&#9;&quot;&quot;&quot;&#10;&#9;Preprocesses the data to prepare for performing prediction with the ARIMA model.&#10;&#10;&#9;Parameters&#10;&#9;----------&#10;&#9;data : pd.DataFrame&#10;&#9;&#9;DataFrame with the dataset.&#10;&#9;Returns&#10;&#9;----------&#10;&#9;date_time_column&#10;&#9;&#9;pd.Series with date_time data.&#10;&#9;prediction_column&#10;&#9;&#9;pd.Series with target data.&#10;&#9;&quot;&quot;&quot;&#10;&#9;date_time_column = pd.Series()&#10;&#9;prediction_column = pd.Series()&#10;&#10;&#9;for name in data.columns.values:&#10;&#9;&#9;attribute_type, attribute_role = data.rm_metadata[name]&#10;&#10;&#9;&#9;if attribute_type == 'date_time':&#10;&#9;&#9;&#9;date_time_column = data[name]&#10;&#9;&#9;if attribute_role == 'prediction':&#10;&#9;&#9;&#9;prediction_column = data[name]&#10;&#10;&#9;return date_time_column, prediction_column&#10;&#10;&#10;def apply_statsmodels(model, data):&#10;&#9;&quot;&quot;&quot;&#10;&#9; Performs out-of-sample forecast on data.&#10;&#10;&#9; Parameters&#10;&#9; ----------&#10;&#9; model : statsmodels.tsa.arima_model.ARIMA&#10;&#9;&#9;Pre-trained ARIMA model.&#10;&#9; data : pd.DataFrame&#10;&#9;&#9;DataFrame with data on which to forecast.&#10;&#10;&#9; Returns&#10;&#9; -------&#10;&#9; result_df&#10;&#9;&#9; DataFrame with out-of-sample forecasts.&#10;&#9; model&#10;&#9;&#9; Fitted ARIMA model.&#10;&#9; &quot;&quot;&quot;&#10;&#9;ARIMA.__getnewargs__ = __getnewargs__&#10;&#10;&#9;date_time_column, prediction_column = preprocessing_statsmodels(data)&#10;&#9;start = date_time_column.iloc[0]&#10;&#9;end = date_time_column.iloc[-1]&#10;&#10;&#9;predictions = model.predict(start=start, end=end, typ='levels')&#10;&#9;result_df = pd.DataFrame(data=predictions.values, columns=[prediction_column.name])&#10;&#9;result_df[date_time_column.name] = date_time_column&#10;&#9;result_df.rm_metadata = {date_time_column.name: ('date_time', 'id'), prediction_column.name: ('real', 'prediction')}&#10;&#10;&#9;return result_df, model&#10;"/>
        <parameter key="params XML definition" value="&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&#10;&#10;&lt;model name=&quot;somename&quot;&gt;&#10;&lt;!-- this will show up as drop down --&gt;&#10;&#9;&lt;parameter name=&quot;loss&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The loss function to be used. Defaults to ‘hinge’, which gives a linear SVM. The ‘log’ loss gives logistic regression, a probabilistic classifier. ‘modified_huber’ is another smooth loss that brings tolerance to outliers as well as probability estimates. ‘squared_hinge’ is like hinge but is quadratically penalized. ‘perceptron’ is the linear loss used by the perceptron algorithm. The other losses are designed for regression but can be useful in classification as well&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;        &lt;value&gt;hinge&lt;/value&gt;&#10;        &lt;value&gt;log&lt;/value&gt;&#10;        &lt;value&gt;modified_huber&lt;/value&gt;&#10;        &lt;value&gt;squared_hinge&lt;/value&gt;&#10;        &lt;value&gt;perceptron&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;squared_loss&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;huber&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;epsilon_insensitive&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;squared_epsilon_insensitive&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;hinge&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as float. The parameters is only visible if parent has values matching the activation_value--&gt;&#10;&#9;&lt;parameter name=&quot;epsilon&quot; parent=&quot;loss&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Epsilon in the epsilon-insensitive loss functions.&lt;/description&gt;&#10;&#9;&#9;&lt;activation_value&gt;huber&lt;/activation_value&gt;&#10;&#9;&#9;&lt;activation_value&gt;epsilon_insensitive&lt;/activation_value&gt;&#10;&#9;&#9;&lt;activation_value&gt;squared_epsilon_insensitive&lt;/activation_value&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.01&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as drop down --&gt;&#10;&#9;&lt;parameter name=&quot;penalty&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The penalty to be used.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;string&lt;/type&gt;&#10;&#9;&#9;&lt;value&gt;none&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;l2&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;l1&lt;/value&gt;&#10;&#9;&#9;&lt;value&gt;elasticnet&lt;/value&gt;&#10;&#9;&#9;&lt;default&gt;l2&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as numeric input box supporting real numbers--&gt;&#10;&#9;&lt;parameter name=&quot;alpha&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Constant that multiplies the regularization term.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.0001&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as checkbox--&gt;&#10;&#9;&lt;parameter name=&quot;fit_intercept&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;bool&lt;/type&gt;&#10;&#9;&#9;&lt;default&gt;True&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&#9;&lt;!-- this will show up as numeric input box supporting Integers only--&gt;&#10;&#9;&lt;parameter name=&quot;max_iter&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;The maximum number of passes over the training data (aka epochs).&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;int&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;1&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Integer.MAX_VALUE&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;5&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;    &lt;parameter name=&quot;n_jobs&quot; is_keyword=&quot;true&quot;&gt;&#10;        &lt;description&gt;Number of CPUs to use to do the One Versus All for multi-class problems.&lt;/description&gt;&#10;        &lt;type&gt;int&lt;/type&gt;&#10;        &lt;min&gt;-1&lt;/min&gt;&#10;        &lt;max&gt;64&lt;/max&gt;&#10;        &lt;default&gt;-1&lt;/default&gt;&#10;    &lt;/parameter&gt;&#10;    &lt;!-- this will only allow positive real numbers --&gt;&#10;&#9;&lt;parameter name=&quot;eta0&quot; is_keyword=&quot;true&quot;&gt;&#10;&#9;&#9;&lt;description&gt;Initial learning rate.&lt;/description&gt;&#10;&#9;&#9;&lt;type&gt;float&lt;/type&gt;&#10;&#9;&#9;&lt;min&gt;0&lt;/min&gt;&#10;&#9;&#9;&lt;max&gt;Double.POSITIVE_INFINITY&lt;/max&gt;&#10;&#9;&#9;&lt;default&gt;0.01&lt;/default&gt;&#10;&#9;&lt;/parameter&gt;&#10;&lt;/model&gt;"/>
      </operator>
      <operator activated="false" class="retrieve" compatibility="9.5.000" expanded="true" height="68" name="Retrieve Golf" width="90" x="45" y="391">
        <parameter key="repository_entry" value="//Samples/data/Golf"/>
      </operator>
      <operator activated="false" class="nominal_to_numerical" compatibility="9.5.000" expanded="true" height="103" name="Nominal to Numerical" width="90" x="246" y="136">
        <parameter key="return_preprocessing_model" value="false"/>
        <parameter key="create_view" value="false"/>
        <parameter key="attribute_filter_type" value="all"/>
        <parameter key="attribute" value=""/>
        <parameter key="attributes" value=""/>
        <parameter key="use_except_expression" value="false"/>
        <parameter key="value_type" value="nominal"/>
        <parameter key="use_value_type_exception" value="false"/>
        <parameter key="except_value_type" value="file_path"/>
        <parameter key="block_type" value="single_value"/>
        <parameter key="use_block_type_exception" value="false"/>
        <parameter key="except_block_type" value="single_value"/>
        <parameter key="invert_selection" value="false"/>
        <parameter key="include_special_attributes" value="true"/>
        <parameter key="coding_type" value="unique integers"/>
        <parameter key="use_comparison_groups" value="false"/>
        <list key="comparison_groups"/>
        <parameter key="unexpected_value_handling" value="all 0 and warning"/>
        <parameter key="use_underscore_in_name" value="false"/>
      </operator>
      <operator activated="true" class="apply_model" compatibility="9.5.000" expanded="true" height="82" name="Apply Model" width="90" x="648" y="136">
        <list key="application_parameters"/>
        <parameter key="create_view" value="false"/>
      </operator>
      <operator activated="true" class="performance_classification" compatibility="9.5.000" expanded="true" height="82" name="Performance" width="90" x="782" y="136">
        <parameter key="main_criterion" value="first"/>
        <parameter key="accuracy" value="true"/>
        <parameter key="classification_error" value="false"/>
        <parameter key="kappa" value="false"/>
        <parameter key="weighted_mean_recall" value="false"/>
        <parameter key="weighted_mean_precision" value="false"/>
        <parameter key="spearman_rho" value="false"/>
        <parameter key="kendall_tau" value="false"/>
        <parameter key="absolute_error" value="false"/>
        <parameter key="relative_error" value="false"/>
        <parameter key="relative_error_lenient" value="false"/>
        <parameter key="relative_error_strict" value="false"/>
        <parameter key="normalized_absolute_error" value="false"/>
        <parameter key="root_mean_squared_error" value="false"/>
        <parameter key="root_relative_squared_error" value="false"/>
        <parameter key="squared_error" value="false"/>
        <parameter key="correlation" value="false"/>
        <parameter key="squared_correlation" value="false"/>
        <parameter key="cross-entropy" value="false"/>
        <parameter key="margin" value="false"/>
        <parameter key="soft_margin_loss" value="false"/>
        <parameter key="logistic_loss" value="false"/>
        <parameter key="skip_undefined_labels" value="true"/>
        <parameter key="use_example_weights" value="true"/>
        <list key="class_weights"/>
      </operator>
      <connect from_op="Retrieve Sonar" from_port="output" to_op="Build Python Model" to_port="training set"/>
      <connect from_op="Create Learner Object" from_port="pythonLearner" to_op="Build Python Model" to_port="pythonlearner"/>
      <connect from_op="Build Python Model" from_port="model" to_op="Apply Model" to_port="model"/>
      <connect from_op="Build Python Model" from_port="exampleSet" to_op="Apply Model" to_port="unlabelled data"/>
      <connect from_op="Apply Model" from_port="labelled data" to_op="Performance" to_port="labelled data"/>
      <connect from_op="Performance" from_port="performance" to_port="result 1"/>
      <portSpacing port="source_input 1" spacing="0"/>
      <portSpacing port="sink_result 1" spacing="0"/>
      <portSpacing port="sink_result 2" spacing="0"/>
    </process>
  </operator>
</process>
